--- /usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py
+++ /usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py
@@ -25,7 +25,7 @@
         This :attr:`momentum` argument is different from one used in optimizer
         classes and the conventional notion of momentum. Mathematically, the
         update rule for running statistics here is
-        :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t`,
+        :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t`,
         where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
         new observed value.
 